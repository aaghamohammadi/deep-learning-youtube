{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3sc6Xoly-bL8"
   },
   "source": [
    "**Transfer Learning**, often abbreviated as TL, is a strategy used in deep learning.\n",
    "\n",
    "In this approach, the knowledge or understanding gained from one task is applied to a similar but different task to improve its performance.\n",
    "\n",
    "To give you an example, let's consider image classification.\n",
    "\n",
    "If a machine learning model has learned to identify cars, that knowledge can be transferred and used when the model is trying to identify trucks.\n",
    "\n",
    "This is because both tasks are related and share common features.\n",
    "\n",
    "So, the model doesn't have to start learning from scratch for the new task, which makes the learning process more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3kfDeQjfUMII"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lp8ZVdVKUBCa",
    "outputId": "ad0b50d8-a8ed-4a97-c221-37e66c058d04"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "assert X_train.shape == (50000, 32, 32, 3)\n",
    "assert X_test.shape == (10000, 32, 32, 3)\n",
    "assert y_train.shape == (50000, 1)\n",
    "assert y_test.shape == (10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Px0jrrEaV2Uk"
   },
   "outputs": [],
   "source": [
    "# Convert the data to TensorFlow Datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = (image / 255.0)\n",
    "    image = tf.image.resize(image, (224,224))\n",
    "    return image, label\n",
    "\n",
    "# Dataset preparation function with augmentation option\n",
    "def prepare_dataset(ds, batch_size=20):\n",
    "    ds = ds.map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    ds = ds.shuffle(buffer_size=10000).batch(batch_size)\n",
    "    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "# Preprocess the data\n",
    "train_ds = prepare_dataset(train_ds)\n",
    "test_ds = prepare_dataset(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndLANVsQUWMB"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "model_url = \"https://www.kaggle.com/models/google/efficientnet-v2/TensorFlow2/imagenet1k-b0-feature-vector/2\"\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        hub.kerasLayer(model_url, trainable=False, input_shape=(224, 224, 3), name=\"feature_extraction_layer\"),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S4-8VhizMd9q",
    "outputId": "e3cf2141-efdd-4c0a-b319-e9a98cea80c4"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l7liaJvcMcCb",
    "outputId": "1c1f6947-57a9-4d0e-ffd4-84eacf441584"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ds, epochs=100, validation_data=test_ds, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQGT41TdY7lQ"
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
