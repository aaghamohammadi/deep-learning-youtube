{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "MASTER_URL_ROOT = \"https://raw.githubusercontent.com/numenta/NAB/master/data/\"\n",
        "\n",
        "datasets = {\n",
        "    \"df_small_noise\": \"artificialNoAnomaly/art_daily_small_noise.csv\",\n",
        "    \"df_daily_jumpsup\": \"artificialWithAnomaly/art_daily_jumpsup.csv\"\n",
        "}\n",
        "\n",
        "def load_dataset(url_suffix):\n",
        "    url = MASTER_URL_ROOT + url_suffix\n",
        "    return pd.read_csv(url, parse_dates=True, index_col=\"timestamp\")\n",
        "\n",
        "df_small_noise = load_dataset(datasets[\"df_small_noise\"])\n",
        "df_daily_jumpsup = load_dataset(datasets[\"df_daily_jumpsup\"])\n",
        "\n",
        "print(\"Small Noise DataFrame shape: \", df_small_noise.shape)\n",
        "print(\"Daily Jumps Up DataFrame shape: \", df_daily_jumpsup.shape)"
      ],
      "metadata": {
        "id": "HwGeMlTG5RS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_small_noise # for every 5 mins for 14 days: 24 * (60/5) * 14"
      ],
      "metadata": {
        "id": "UQOaDyKx5X-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_dataframe(df, title):\n",
        "    fig, ax = plt.subplots()\n",
        "    df.plot(legend=False, ax=ax)\n",
        "    ax.set_title(title)\n",
        "    plt.show()\n",
        "\n",
        "plot_dataframe(df_small_noise, \"Small Noise Data\")\n",
        "plot_dataframe(df_daily_jumpsup, \"Daily Jumps Up Data\")"
      ],
      "metadata": {
        "id": "etHj8hZB9YrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_mean = df_small_noise.mean()\n",
        "training_std = df_small_noise.std()\n",
        "df_training_value = (df_small_noise - training_mean) / training_std"
      ],
      "metadata": {
        "id": "sJ4Y8YpJ-DfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "TIME_STEPS = 288\n",
        "\n",
        "def create_sequences(data, time_steps=TIME_STEPS):\n",
        "    sequences = []\n",
        "    for start_idx in range(len(data) - time_steps + 1):\n",
        "        end_idx = start_idx + time_steps\n",
        "        sequences.append(data[start_idx:end_idx])\n",
        "    return np.stack(sequences)\n",
        "\n",
        "training_data = df_training_value.values\n",
        "\n",
        "x_train = create_sequences(training_data)\n",
        "\n",
        "print(\"Training input shape: \", x_train.shape)"
      ],
      "metadata": {
        "id": "u_FbD6t2-5nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Input(shape=(x_train.shape[1], x_train.shape[2])),\n",
        "        tf.keras.layers.Conv1D(\n",
        "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
        "        ),\n",
        "        tf.keras.layers.Dropout(rate=0.2),\n",
        "        tf.keras.layers.Conv1D(\n",
        "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
        "        ),\n",
        "        tf.keras.layers.Conv1DTranspose(\n",
        "            filters=16, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
        "        ),\n",
        "        tf.keras.layers.Dropout(rate=0.2),\n",
        "        tf.keras.layers.Conv1DTranspose(\n",
        "            filters=32, kernel_size=7, padding=\"same\", strides=2, activation=\"relu\"\n",
        "        ),\n",
        "        tf.keras.layers.Conv1DTranspose(filters=1, kernel_size=7, padding=\"same\"),\n",
        "\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "T3l3bqkL_3Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    x_train,\n",
        "    x_train,\n",
        "    epochs=50,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
        "    ],\n",
        ")"
      ],
      "metadata": {
        "id": "xc1wsXjSC8sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3zoVaScVDsDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_pred = model.predict(x_train)\n",
        "train_mae_loss = np.mean(np.abs(x_train_pred - x_train), axis=1)\n",
        "\n",
        "plt.hist(train_mae_loss, bins=50)\n",
        "plt.xlabel(\"Train MAE loss\")\n",
        "plt.ylabel(\"No of samples\")\n",
        "plt.show()\n",
        "\n",
        "threshold = np.max(train_mae_loss)\n",
        "print(\"Reconstruction error threshold: \", threshold)"
      ],
      "metadata": {
        "id": "6tVlQgO5Dvao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x_train[0])\n",
        "plt.plot(x_train_pred[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "E-T82IQaEJ_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_value = (df_daily_jumpsup - training_mean) / training_std\n",
        "x_test = create_sequences(df_test_value.values)\n",
        "print(\"Test input shape: \", x_test.shape)\n",
        "\n",
        "x_test_pred = model.predict(x_test)\n",
        "test_mae_loss = np.mean(np.abs(x_test_pred - x_test), axis=1)\n",
        "test_mae_loss = test_mae_loss.reshape((-1))\n",
        "\n",
        "plt.hist(test_mae_loss, bins=50)\n",
        "plt.xlabel(\"test MAE loss\")\n",
        "plt.ylabel(\"No of samples\")\n",
        "plt.show()\n",
        "\n",
        "anomalies = test_mae_loss > threshold\n",
        "print(\"Number of anomaly samples: \", np.sum(anomalies))\n",
        "print(\"Indices of anomaly samples: \", np.where(anomalies))"
      ],
      "metadata": {
        "id": "rm8QXNMOEO8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_anomalous_indices(anomalies, time_steps, data_length):\n",
        "    anomalous_indices = []\n",
        "    for idx in range(time_steps - 1, data_length - time_steps + 1):\n",
        "        if np.all(anomalies[idx - time_steps + 1 : idx]):\n",
        "            anomalous_indices.append(idx)\n",
        "    return anomalous_indices\n",
        "\n",
        "data_length = len(df_test_value)\n",
        "\n",
        "anomalous_data_indices = find_anomalous_indices(anomalies, TIME_STEPS, data_length)\n",
        "\n",
        "print(\"Anomalous data indices: \", anomalous_data_indices)"
      ],
      "metadata": {
        "id": "EavJNtzvE3Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset = df_daily_jumpsup.iloc[anomalous_data_indices]\n",
        "fig, ax = plt.subplots()\n",
        "df_daily_jumpsup.plot(legend=False, ax=ax)\n",
        "df_subset.plot(legend=False, ax=ax, color=\"r\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gZhdTkvOE6JS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}