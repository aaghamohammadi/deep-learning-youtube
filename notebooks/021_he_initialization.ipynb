{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "def load_dataset(dataset_name, split):\n",
        "    ds, ds_info = tfds.load(dataset_name, split=split, shuffle_files=True, with_info=True, as_supervised=True)\n",
        "    return ds, ds_info\n",
        "\n",
        "def shuffle_dataset(ds):\n",
        "    buffer_size = tf.data.experimental.cardinality(ds).numpy()\n",
        "    return ds.shuffle(buffer_size)\n",
        "\n",
        "def split_dataset(ds, train_ratio=0.9):\n",
        "    num_examples = tf.data.experimental.cardinality(ds).numpy()\n",
        "    num_train = int(train_ratio * num_examples)\n",
        "    train_ds = ds.take(num_train)\n",
        "    test_ds = ds.skip(num_train)\n",
        "    return train_ds, test_ds\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = (image / 127.5) - 1\n",
        "    image = tf.image.resize(image, (224, 224))\n",
        "    return image, label\n",
        "\n",
        "def prepare_dataset(ds, batch_size=32):\n",
        "    return ds.map(preprocess).batch(batch_size)\n",
        "\n",
        "# Load the Caltech-101 dataset\n",
        "train_ds, ds_info = load_dataset('caltech101', 'train')\n",
        "test_ds, _ = load_dataset('caltech101', 'test')\n",
        "\n",
        "# Concatenate the train and test datasets\n",
        "all_ds = train_ds.concatenate(test_ds)\n",
        "\n",
        "# Shuffle the combined dataset\n",
        "all_ds = shuffle_dataset(all_ds)\n",
        "\n",
        "# Split the combined dataset into train and test datasets\n",
        "train_ds, test_ds = split_dataset(all_ds)\n",
        "\n",
        "# Prepare the datasets for training\n",
        "train_ds = prepare_dataset(train_ds)\n",
        "test_ds = prepare_dataset(test_ds)"
      ],
      "metadata": {
        "id": "flLOriOwHF38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu', kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(256, activation='relu', kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(128, activation='relu', kernel_initializer=\"he_normal\"),\n",
        "    tf.keras.layers.Dense(ds_info.features['label'].num_classes, activation='softmax')  # Update the output layer to match the number of classes in the dataset\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(momentum=0.9, learning_rate=0.001, nesterov=True), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "n8ATAf0GkIEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=2, min_lr=0.0001)\n",
        "# lr * factor (0-1)\n",
        "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=5, restore_best_weights=True)\n",
        "\n",
        "callbacks = [early_stopping, reduce_lr] # callbacks list"
      ],
      "metadata": {
        "id": "jbEYr1xnLvtz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(train_ds, epochs=20, validation_data=test_ds, batch_size=32, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "IKzShaposBXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "SJaRnIQ9-Hxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def get_random_batches(test_ds, num_batches=4):\n",
        "    return np.random.choice(len(test_ds), size=num_batches, replace=False)\n",
        "\n",
        "def get_random_image_and_labels(test_ds, batch):\n",
        "    images, labels = list(test_ds)[batch]\n",
        "    index = np.random.choice(len(images), size=1)[0]\n",
        "    return images[index], labels[index]\n",
        "\n",
        "def predict_labels(model, images):\n",
        "    y_probs_batch = model.predict(images)\n",
        "    return np.argmax(y_probs_batch, axis=-1)\n",
        "\n",
        "def plot_image(ax, image, true_label, pred_label):\n",
        "    ax.set_axis_off()\n",
        "    image_to_show = (image + 1) / 2\n",
        "    ax.imshow(image_to_show.numpy(), cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    title = f'True: {true_label}, Pred: {pred_label}'\n",
        "    ax.set_title(title, color='green' if true_label == pred_label else 'red')\n",
        "\n",
        "def plot_images(model, test_ds, class_names):\n",
        "    batches = get_random_batches(test_ds)\n",
        "    _, axes = plt.subplots(nrows=1, ncols=len(batches), figsize=(20, 6))\n",
        "    for i, batch in enumerate(batches):\n",
        "        image, true_label = get_random_image_and_labels(test_ds, batch)\n",
        "        y_pred_batch = predict_labels(model, image[None, ...])\n",
        "        pred_label = class_names[y_pred_batch[0]]\n",
        "        true_label = class_names[true_label.numpy()]\n",
        "        plot_image(axes[i], image, true_label, pred_label)\n",
        "    plt.setp(axes, xticks=[], xticklabels=[], yticklabels=[])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Get the class names from ds_info\n",
        "class_names = ds_info.features['label'].names\n",
        "\n",
        "# Plot the images with the actual and predicted labels\n",
        "plot_images(model, test_ds, class_names)"
      ],
      "metadata": {
        "id": "EJuEE9ltnhcS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}