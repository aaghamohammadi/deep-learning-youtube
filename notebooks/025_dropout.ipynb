{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Dropout is a technique used to reduce overfitting in neural networks.\n",
        "\n",
        "It works by randomly setting neurons to zero with a probability of $\\mu$, typically 50%, at each iteration during training."
      ],
      "metadata": {
        "id": "5QRLWXVxa5Pd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "3kfDeQjfUMII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lp8ZVdVKUBCa"
      },
      "outputs": [],
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "assert X_train.shape == (50000, 32, 32, 3)\n",
        "assert X_test.shape == (10000, 32, 32, 3)\n",
        "assert y_train.shape == (50000, 1)\n",
        "assert y_test.shape == (10000, 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the data to TensorFlow Datasets\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = (image / 127.5) - 1\n",
        "    image = tf.image.resize(image, (32, 32))\n",
        "    return image, label\n",
        "\n",
        "def prepare_dataset(ds, batch_size=100):\n",
        "    return ds.map(preprocess).batch(batch_size)\n",
        "\n",
        "# Preprocess the data\n",
        "train_ds = prepare_dataset(train_ds)\n",
        "test_ds = prepare_dataset(test_ds)"
      ],
      "metadata": {
        "id": "Px0jrrEaV2Uk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
        "        tf.keras.layers.Dropout(0.5),  # Dropout layer\n",
        "        tf.keras.layers.Dense(256, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
        "        tf.keras.layers.Dropout(0.5),  # Dropout layer\n",
        "        tf.keras.layers.Dense(128, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
        "        tf.keras.layers.Dropout(0.5),  # Dropout layer\n",
        "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(momentum=0.9, learning_rate=0.01, nesterov=True),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor=\"val_accuracy\", factor=0.2, patience=5, min_lr=0.001\n",
        ")\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor=\"val_accuracy\", patience=15, restore_best_weights=True\n",
        ")\n",
        "callbacks = [early_stopping, reduce_lr]\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_ds, epochs=100, validation_data=test_ds, batch_size=100, callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "ndLANVsQUWMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AQGT41TdY7lQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}