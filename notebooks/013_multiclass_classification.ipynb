{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Until now, we have discussed binary classification. Now, it's time to talk about multiclass classification, where we categorize the output into different $I$ categories. Recall the deep neural architecture:\n",
        "\n",
        "\\begin{align*}\n",
        "h_1 & = \\text{ReLU}(\\beta_0 + \\mathbf{\\Omega}_0x), \\\\\n",
        "h_2 & = \\text{ReLU}(\\beta_1 + \\mathbf{\\Omega}_1h_1), \\\\\n",
        "h_3 & = \\text{ReLU}(\\beta_2 + \\mathbf{\\Omega}_2h_2), \\\\\n",
        "& \\vdots \\\\\n",
        "h_K & = \\text{ReLU}(\\beta_{K-1} + \\mathbf{\\Omega}_{K-1}h_{K-1}), \\\\\n",
        "y & = \\beta_K + \\mathbf{\\Omega}_K h_K.\n",
        "\\end{align*}\n",
        "\n",
        "Firstly, we need $y$ to have $I$ elements, where each $y_j \\in \\mathbb{R}$ for $j= 1, \\cdots, I$.\n",
        "\n",
        "Secondly, we want $y_j$ to represent the probability that the output belongs to class $j$.\n",
        "\n",
        "To this end, we use the softmax activation function.\n",
        "\n",
        "The softmax function is used in multiclass classification problems where we want to classify an input into one of multiple possible categories. It converts a vector of real numbers into a probability distribution.\n",
        "\n",
        "Each output $y_j$ of the softmax function represents the probability that the input belongs to class $j$.\n",
        "Given an input vector $y = [y_1, y_2, ..., y_I]$, the softmax function computes the exponential of each element $y_j$, and then normalizes these values by dividing by the sum of all these exponentials. This results in a vector of the same length as $y$, but with all elements between 0 and 1, and the entire vector sums to 1.\n",
        "\n",
        "Mathematically, this is represented as:\n",
        "\n",
        "$$\n",
        "\\text{softmax}_j(y) = \\frac{\\exp\\left[y_j\\right]}{\\Sigma_{i=1}^{I}\\exp\\left[y_i\\right]}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "V0To3W_ie0TD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhWf67ydemLy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def softmax(y):\n",
        "    # Compute the exponentials of each element in the input vector\n",
        "    exps = np.exp(y)\n",
        "    # Normalize the exponentials by dividing by the sum of all exponentials\n",
        "    softmax_output = exps / np.sum(exps)\n",
        "    return softmax_output\n",
        "\n",
        "y = np.array([1.0, 2.0, 3.0])\n",
        "print(softmax(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's tackle a real-world multiclass classification problem. Our goal is to recognize images of handwritten digits ranging from 0 to 9."
      ],
      "metadata": {
        "id": "3TRuoheui8p5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
        "for ax, image, label in zip(axes, digits.images, digits.target):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
        "    ax.set_title(\"Training: %i\" % label)"
      ],
      "metadata": {
        "id": "71EjKScbjO2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flatten the images\n",
        "n_samples = len(digits.images)\n",
        "data = digits.images.reshape((n_samples, -1))\n",
        "\n",
        "# Split data into 90% train and 10% test subsets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data, digits.target, test_size=0.1, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "zaaP8KOhjiTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {accuracy*100:.2f}%')"
      ],
      "metadata": {
        "id": "n8ATAf0GkIEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Predict the probabilities for each class\n",
        "y_probs = model.predict(X_test)\n",
        "\n",
        "# Get the class with the highest probability for each sample\n",
        "y_pred = np.argmax(y_probs, axis=-1)\n",
        "\n",
        "# Select four random indices from the test data\n",
        "indices = np.random.choice(len(X_test), size=4, replace=False)\n",
        "\n",
        "# Plot the images with the actual and predicted labels\n",
        "_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))\n",
        "for ax, image, true_label, pred_label in zip(axes, X_test[indices].reshape(-1, 8, 8), y_test[indices], y_pred[indices]):\n",
        "    ax.set_axis_off()\n",
        "    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
        "    title = f'True: {true_label}, Pred: {pred_label}'\n",
        "    ax.set_title(title, color='green' if true_label == pred_label else 'red')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EJuEE9ltnhcS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}