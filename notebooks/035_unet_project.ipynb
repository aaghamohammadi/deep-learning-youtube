{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ2rmvN91veV"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)"
      ],
      "metadata": {
        "id": "QSV1Sum72DGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(input_image, input_mask):\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "  input_mask -= 1\n",
        "  return input_image, input_mask"
      ],
      "metadata": {
        "id": "GRhfz2Ut2X9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
        "  input_mask = tf.image.resize(\n",
        "    datapoint['segmentation_mask'],\n",
        "    (128, 128),\n",
        "    method = tf.image.ResizeMethod.NEAREST_NEIGHBOR,\n",
        "  )\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask"
      ],
      "metadata": {
        "id": "e7fuah6n3AaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_LENGTH = info.splits['train'].num_examples\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE"
      ],
      "metadata": {
        "id": "s9gZjBb23GGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = dataset['train'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "test_images = dataset['test'].map(load_image, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "Dvn0ILFM3JrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Augment(tf.keras.layers.Layer):\n",
        "  def __init__(self, seed=42):\n",
        "    super().__init__()\n",
        "    self.augment_inputs = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n",
        "    self.augment_labels = tf.keras.layers.RandomFlip(mode=\"horizontal\", seed=seed)\n",
        "\n",
        "  def call(self, inputs, labels):\n",
        "    inputs = self.augment_inputs(inputs)\n",
        "    labels = self.augment_labels(labels)\n",
        "    return inputs, labels"
      ],
      "metadata": {
        "id": "KlKGTIHp3Ppm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_batches = (\n",
        "    train_images\n",
        "    .cache()\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .repeat()\n",
        "    .map(Augment())\n",
        "    .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
        "\n",
        "test_batches = test_images.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "mmQJiCvE3VZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "4SRA539L3aOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for images, masks in train_batches.take(2):\n",
        "  sample_image, sample_mask = images[0], masks[0]\n",
        "  display([sample_image, sample_mask])"
      ],
      "metadata": {
        "id": "fBiODwjV3dBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "# Inspired by the paper \"U-Net: Convolutional Networks for Biomedical Image Segmentation\" (https://arxiv.org/abs/1505.04597)\n",
        "\n",
        "\n",
        "# Display image\n",
        "Image(filename='unet.png', width=1200)"
      ],
      "metadata": {
        "id": "3rUXu5TweNti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, Dropout\n",
        "\n",
        "def conv2d_block(input_tensor, num_filters):\n",
        "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
        "    x = Conv2D(num_filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(input_tensor)\n",
        "    x = Dropout(0.1)(x)\n",
        "    x = Conv2D(num_filters, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(x)\n",
        "    return x\n",
        "\n",
        "def encoder_block(inputs, num_filters):\n",
        "    \"\"\"Function to add 2 convolutional blocks and then perform max pooling on it.\"\"\"\n",
        "    conv_block = conv2d_block(inputs, num_filters)\n",
        "    x = MaxPooling2D((2, 2))(conv_block)\n",
        "    return conv_block, x\n",
        "\n",
        "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
        "    \"\"\"Function to perform an upconvolution and then concatenate the result with the shortcut from encoder, followed by 2 convolution blocks\"\"\"\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
        "    x = concatenate([x, concat_tensor])\n",
        "    x = conv2d_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "# Build U-Net model\n",
        "inputs = Input((128, 128, 3))\n",
        "s = inputs\n",
        "\n",
        "# Encoder\n",
        "encoder1_block, pool1 = encoder_block(s, 16)\n",
        "encoder2_block, pool2 = encoder_block(pool1, 32)\n",
        "encoder3_block, pool3 = encoder_block(pool2, 64)\n",
        "encoder4_block, pool4 = encoder_block(pool3, 128)\n",
        "\n",
        "# Bridge\n",
        "bridge = conv2d_block(pool4, 256)\n",
        "\n",
        "# Decoder\n",
        "decoder1_block = decoder_block(bridge, encoder4_block, 128)\n",
        "decoder2_block = decoder_block(decoder1_block, encoder3_block, 64)\n",
        "decoder3_block = decoder_block(decoder2_block, encoder2_block, 32)\n",
        "decoder4_block = decoder_block(decoder3_block, encoder1_block, 16)\n",
        "\n",
        "outputs = Conv2D(3, (1, 1), activation='softmax')(decoder4_block)\n",
        "\n",
        "model = Model(inputs=[inputs], outputs=[outputs])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "E003F-1q3wbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True, expand_nested=True)"
      ],
      "metadata": {
        "id": "9eoFKJGw5LKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mask(pred_mask):\n",
        "  pred_mask = tf.math.argmax(pred_mask, axis=-1)\n",
        "  pred_mask = pred_mask[..., tf.newaxis]\n",
        "  return pred_mask[0]\n",
        "\n",
        "def show_predictions(dataset=None, num=1):\n",
        "  if dataset:\n",
        "    for image, mask in dataset.take(num):\n",
        "      pred_mask = model.predict(image)\n",
        "      display([image[0], mask[0], create_mask(pred_mask)])\n",
        "  else:\n",
        "    display([sample_image, sample_mask,\n",
        "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])\n",
        "show_predictions()"
      ],
      "metadata": {
        "id": "1SVIs5JR5Pmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "class DisplayCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    clear_output(wait=True)\n",
        "    show_predictions()\n",
        "    print (f'\\nSample Prediction after epoch {epoch+1}\\n')"
      ],
      "metadata": {
        "id": "A4ONfFUF5iO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 50\n",
        "VAL_SUBSPLITS = 5\n",
        "VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n",
        "\n",
        "model_history = model.fit(train_batches, epochs=EPOCHS,\n",
        "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
        "                          validation_steps=VALIDATION_STEPS,\n",
        "                          validation_data=test_batches,\n",
        "                          callbacks=[DisplayCallback()])"
      ],
      "metadata": {
        "id": "2JKypg0P5t3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(model_history.epoch, loss, 'r', label='Training loss')\n",
        "plt.plot(model_history.epoch, val_loss, 'bo', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v0LR_3rM6HsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_predictions(test_batches, 3)"
      ],
      "metadata": {
        "id": "yQaDGvD66LEG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}