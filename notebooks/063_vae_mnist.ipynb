{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwYBi5fqCxYO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "metadata": {
        "id": "nF-qpQW5DwUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_width = x_train.shape[1]\n",
        "image_height = x_train.shape[2]\n",
        "num_channels = 1\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], image_height, image_width, num_channels)\n",
        "x_test = x_test.reshape(x_test.shape[0], image_height, image_width, num_channels)\n",
        "\n",
        "input_shape = (image_height, image_width, num_channels)"
      ],
      "metadata": {
        "id": "gVX-SCFynsdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "sEtThJA0GbhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 8\n",
        "\n",
        "input_img = tf.keras.layers.Input(shape=input_shape, name=\"encoder_input\")\n",
        "x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\")(input_img)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\", strides=(2,2))(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "\n",
        "conv_shape = tf.keras.backend.int_shape(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(32, activation=\"relu\", kernel_initializer=\"he_normal\")(x)"
      ],
      "metadata": {
        "id": "VoG4tT6oE9P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z_mu = tf.keras.layers.Dense(latent_dim, name=\"z_mu\")(x)\n",
        "z_log_sigma = tf.keras.layers.Dense(latent_dim, name=\"z_log_sigma\")(x)"
      ],
      "metadata": {
        "id": "0SuvRajMGoI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sampling(args):\n",
        "    z_mu, z_log_sigma = args\n",
        "    epsilon = tf.keras.backend.random_normal(shape=(tf.keras.backend.shape(z_mu)[0], latent_dim), mean=0., stddev=1.)\n",
        "    return z_mu + (tf.keras.backend.exp(z_log_sigma) ** 0.5) * epsilon"
      ],
      "metadata": {
        "id": "u72OlHjHIEAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = tf.keras.layers.Lambda(sampling, output_shape=(latent_dim,), name=\"z\")([z_mu, z_log_sigma])"
      ],
      "metadata": {
        "id": "vPTKNYTAJRvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = tf.keras.models.Model(inputs=input_img, outputs=z, name=\"encoder\")\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "aH0n1hUMJTZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_input = tf.keras.layers.Input(shape=(latent_dim,), name=\"decoder_input\")\n",
        "x = tf.keras.layers.Dense(conv_shape[1] * conv_shape[2] * conv_shape[3], activation=\"relu\", kernel_initializer=\"he_normal\")(decoder_input)\n",
        "x = tf.keras.layers.Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\", strides=(2,2))(x)\n",
        "x = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n",
        "x = tf.keras.layers.Conv2D(filters=1, kernel_size=3, padding='same', activation='sigmoid', name='decoder_output')(x)\n",
        "decoder = tf.keras.models.Model(decoder_input, x, name='decoder')\n",
        "decoder.summary()"
      ],
      "metadata": {
        "id": "xAp7K_dqKYBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_output = decoder(z)"
      ],
      "metadata": {
        "id": "8bA9zdWuMiuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VAELossLayer(tf.keras.layers.Layer):\n",
        "    def vae_loss(self, x, decoder_output, z_mu, z_log_sigma):\n",
        "        x = tf.keras.backend.flatten(x)\n",
        "        decoder_output = tf.keras.backend.flatten(decoder_output)\n",
        "\n",
        "        reconstruction_loss = tf.keras.metrics.binary_crossentropy(x, decoder_output)\n",
        "\n",
        "        kl_loss = -0.5 * tf.keras.backend.sum(1 + z_log_sigma - tf.keras.backend.square(z_mu) - tf.keras.backend.exp(z_log_sigma), axis=-1)\n",
        "\n",
        "        return reconstruction_loss + kl_loss\n",
        "\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, decoder_output, z_mu, z_log_sigma = inputs\n",
        "        loss = self.vae_loss(x, decoder_output, z_mu, z_log_sigma)\n",
        "        self.add_loss(loss)\n",
        "        return x\n",
        "\n",
        "y = VAELossLayer()([input_img, decoder_output, z_mu, z_log_sigma])\n",
        "\n",
        "vae = tf.keras.models.Model(inputs=[input_img], outputs=[y], name='vae')\n",
        "\n",
        "vae.compile(optimizer='adam', loss=None)\n",
        "vae.summary()"
      ],
      "metadata": {
        "id": "Yd3_Z-QfMwZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vae.fit(x=x_train, y=None, epochs = 10, batch_size = 32)"
      ],
      "metadata": {
        "id": "4rfE2ANsRaqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "img_width, img_height = 28, 28\n",
        "sample_vector = np.array([[1, 1, 1, 1, 1, 1, 1, 1]])\n",
        "\n",
        "decoded_example = decoder.predict(sample_vector)\n",
        "\n",
        "decoded_example_reshaped = decoded_example.reshape(img_width, img_height)\n",
        "\n",
        "fig = plt.figure(figsize=(img_width/100, img_height/100), dpi=100)\n",
        "ax = fig.add_subplot(111)\n",
        "ax.imshow(decoded_example_reshaped, cmap='gray')\n",
        "ax.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lWzuJe6gmzay"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}